---
title: "ProjectPWS Summary Writeup"
author: "Jared Casale and Maruthi Ram Nadakuduru"
date: "`r Sys.Date()`"
output: rmarkdown::html_vignette
vignette: >
  %\VignetteIndexEntry{Vignette Title}
  %\VignetteEngine{knitr::rmarkdown}
  \usepackage[utf8]{inputenc}
---

ProjectPWS is the package written for STAT290 by Jared Casale and Maruthi Ram 
Nadakuduru. It aimed to fulfil the requirements of the suggested project topic 
relating to querying the Weather Underground website for PWS data. The basic 
requirements were roughly as follows:

1. Provide a means of querying the website to retrieve all PWS near a location 
(e.g. zipcode + distance) or within a region (e.g. a country name). This should 
also be persistable.
2. Store this data in an S4 class (Note: we are using an R6 class for our 
project). This table should have methods to check validity and extract 
subtables based on similar queries from 1.
3. A function to retrieve weather data for these stations, giving a start and 
end time.
4. Function(s) to visualize the data, in particular to view patterns of 
microclimate.
5. A basic computational facility to approximate missing data values.

The following discusses some known issues/quirks and then each requirement is 
addressed with sample code where appropriate.

## Credits
Please note that CSS file included in the shiny UI and the panel designs are inspired by the Shiny SuperZip example on the Shiny RStudio website
Here is a link to the website
http://shiny.rstudio.com/gallery/superzip-example.html

We have also referred to many examples of Shiny packages in the 'Show me Shiny' website to get ideas on how to design the UI components. Here is a link to that website  http://www.showmeshiny.com/


## Known issues/quirks
### Weather Underground API Key
Use of the API requires an API key. The free tier pricing provides a key with 
severe call limitations, namely 10 calls per minute. Note that each geolookup 
requires a single call and filling a region requires a call to get all cities 
in that region, followed by a call for each city returned to get the stations. 
More restrictive is the fact that the weather history (loading weather data) 
requires a call for each station, for each day in the period. This leads to a 
LOT of calls in a short period. We have provided a key with the package that 
will surely be revoked after too much usage. To work around this, the user would
need to obtain their own key and set the environment variable 
"WUNDERGROUND_API_KEY". All functions would then pick up this variable before 
each new call. The .onAttach function checks for an environment variable with
a key, and sets the default if it is missing. .onDetach will clear this variable
if it is still the default.


### Functions vs R6 methods
We began writing the project with an S4 class, then moved to R6. Unfortunately, 
we couldn't find a great way of documenting the class and chose to leave the 
bulk of our code as separate functions that require one of the R6 objects to be 
passed to it. The result is no different and the object is still the way to 
handle state for all of the actions.

### Shiny Issues
There are a couple of issues with the Shiny UI we could not resolve in time and
here are the details:

1. Load Local File Option on Stations Tab - If the user loads a file that is not a PWStations R6 object we were able to through a error message, however if the user then loads a valid PWStations object file the error continues to be thrown. In this case the user will have to shutdown the application and restart it.
2. Pop-ups on the Weather Tab - We put in shiny code to display a pop-up if the user clicked on the markers for the stations to show the station ID and the weather parameter. But the pop-ups still do not work.
  
## Requirement 1: Querying for PWS

To load PWS data, we have a method calleed getStations. It queries the 
WUnderground API to get all PWS meeting the specified criteria. Valid queries 
for location are as follows:

* A numeric vector specifying a lat/long pair.
* A US zipcode character string.
* A US state or non-US country name.
* A US state and city pair.
* A non-US country name and city pair.

The API limits to PWS within 40km (around 25 miles) of the zipcode and only the 
first 50 results. An optional numeric mile radius restriction may be supplied, 
limiting to stations within that distance from the specified location. Anything 
greater than 24 will be ignored (due to the API limitation).

Within the code, we query the API and parse the resulting XML to save the 
results of the lookup. If a state or country is supplied without a city, then 
the results of the first lookup give a list of cities within that location. This
function then performs a separate query for each of the region/city pairs and 
concatenates the resulting stations. The following code shows sample queries, 
but requires internet connectivity (skipped in this document):

```{r, eval=FALSE}
library(ProjectPWS)

# Charlotte
latLongStations <- getStations(latlong = c(35.229, -80.8433), radius = 2)
zipStations <- getStations(zip = "90210", radius = 10)
berlinStations <- getStations(country = "Germany", city = "Berlin")
cityStations <- getStations(state = "OR", city = "Portand", radius = 3)
countryStations <- getStations(country = "Spain")
```

## Requirement 2: Store in a class
We started out using an S4 class but preferred to use an R6 class. The class 
PWStations is the container that we load data into. It performs some basic 
validation of the query used to create the table in the initialize() function 
and stores the data used for the query. Calling getStations() will associate a 
data table of PWS stations from the resulting query with the object. Likewise, 
calling loadWeatherData() will create a list of data tables corresponding to the 
weather data retrieved for each station in the query. This list is also 
associated with the original class.

To extract subtables, we have a function called makeStationSubtable(). It 
returns a PWStations object with the specified filter applied to the original 
PWStations. If the original object contained weather data, this will also be 
filtered to the appropriate stations. Filter options are one of the following:

1. Reducing the radius of the original query, so that only stations
2. within the new radius are kept.
3. Choosing a number of closest or farthest stations from the original
4. query location.
5. Choosing a set of stations by name.

The following code will extract some subtables from a preloaded object (output 
suppressed):

```{r, eval=FALSE}
charlotteStations <- getStations(latlong = c(35.229, -80.8433), 
                                 radius = 10)
# Decrease radius to 5 miles
makeStationSubtable(charlotteStations, 
                    newRadius = 5)
# Keep 3 closest
makeStationSubtable(charlotteStations, 
                    numberToKeep = 3) 
# Keep 3 farthest
makeStationSubtable(charlotteStations, 
                    numberToKeep = 3, 
                    nearest = FALSE)
makeStationsSubtable(charlotteStations,
                      stationNames = c("KNCCHARL71", "KNCCHARL83"))
```

## Requirement 3: Load weather data for a time period
Loading weather data is achieved through the loadWeatherData() function. It 
takes a start and end date, as well as a start and end hour (between 0 and 23) 
and retrieves a set of temperature variables for each PWS in the PWStations 
object for that time period. The result is stored as a list of data tables, 
with a measurement for each hour in the specified time period, for the set of 
temperature variables. The default variables are temperature, humidity, 
pressure, wind speed and a plain-text set of conditions. To achieve this, it 
records the first measurement it receives for each hour (data from PWS is 
generally at 5 minute intervals). Any missing hours are filled with NAs. Note 
that the API allows for a query of weather history for a single day at a time. 
As a result, loading of weather data requires a total of (number of stations * 
number of variables) calls, which can rapidly lead to exceeding of free Weather 
Underground API restrictions. To help with this, an optional station limit can 
be provided so that only a fixed number of stations are queried. The function 
will output some progress messages so the user knows something is working.

Some examples of loading weather data are as follows (not run due here):

```{r, eval=FALSE}
stations <- getStations(zip = "98107", radius = 2)
weatherData <- loadWeatherData(stations, startDate = "3/3/2015",
                               startHour = 9,
                               endHour = 5,
                               stationLimit = 1)

# Just temperature and humidity
# Startdate defaults to 0, endDate to current date
weatherData2 <- loadWeatherData(stations, 
                                startDate = "3/1/2015",
                                endDate = "3/3/2015", 
                                weatherVars = c("tempi",
                                                "hum")
                                stationLimit = 3)
```

## Requirement 4: Visualizing the data
As per the project requirements the user can do the following tasks - 

* Get the List Weather Stations for:

    * Range of Miles from a Zip Code
    * State
    * Country
    * Locally loaded PWStation Object

* Get the Weather information for the selected stations within a starting and
  ending time range. 

* Download the stations and weather data as a PWStations Object(.rds) into 
  their local system.

Here are the main Use Cases the Shiny User Interface covers - 

* Use Case 1 - 'Get Stations': As mentioned above the user can select from four
  options on the 'Stations Map' tab -
  
    * Zip Code (with Range)
    * State
    * Country 
    * Local File Load
  
  Once the user selects one of the options from the 'Input Type' dropdown, they 
  are presented with the appropriate selection criteria. Once they enter the 
  station selection criteria they will have to hit the 'Get Stations' button to 
  retrieve the stations. The Map automatically zooms in to a level that covers 
  all the stations returned, also marking the stations on the map. The user can
  zoom in and out of the map but the map stays centered at the stations just 
  retrieved.
  The user can look at the retrieved stations data in a table format on the 
  'Data Table' tab. On that tab the user can see a histogram that gives the 
  number of stations within given distance. Below the histogram the station 
  data is displayed as data table that can be filtered and sorted on the screen
  The 'Save Data Locally' button is provided on the top right of the screen on
  this tab and the details of it are explained in the download data use case 
  below.

* Use Case 2 - 'Get Weather': Once the stations are retrieved, the user can 
  go to the 'Weather Map' tab and enter the start and end times on the 'Weather
  Selection Criteria' panel. After providing the date/time range, they will 
  have to click on the 'Get Weather' button to fetch the weather data. 
  Once the weather data is fetched the following things happen - 

    * The map zooms in to a level that covers all the stations just like the 
      stations map. This time the stations are color coded based on the weather 
      attribute selected. 
    * Under the 'Get Weather' button, a drop down to select each hour in the 
      selected time range is provided along with a drop down to select the 
      weather attribute - 'Temperature','Humidity','Wind Speed' and 'Pressure'.
      Also a legend of the color codes used to mark the stations is thrown.

* Use Case 3 - Downloading Data: If the user wishes to save the stations data 
  or the stations data along with the weather data, they can go to the 
  'Data Table' tab and click on the 'Save Data Locally' button on the top right
  side of the page. The data stored depends on what was retrieved at the point
  when the button was clicked. If only the stations data was retrieved at that
  point only that information gets saved locally. The files are named by 
  default based on the station selection criteria but the user has the option 
  to change the name in the windows download box that is thrown. 

* Use Case 4 - Loading Local Data: This option is slightly different from the 
  other station selection criteria. The loaded file has to be a PWStations 
  object that was downloaded through this application. The user will have to 
  select the file and then click on 'Get Stations' button to show the data on 
  the 'Stations Map' and 'Data Table' tabs. In the back end none of the API 
  calls are made, instead data is loaded from the local file as expected.
  Even if the weather data was saved along with this file, the 'Weather Map' 
  tab does not load the Weather Data automatically. The user will again have to
  provide the starting time and ending time to get the data. If the time range 
  provided is the same as the time range of the weather data in the local file
  then the weather data is loaded directly from the file. If they are not the
  same then the API calls are made to get the weather data for the new time
  range provided. 
  
## Requirement 5: Approximating missing data
Missing data did not seem to be a huge issue since we are limiting to hourly 
intervals and PWS generally seemed to provide data for each hour that we 
queried. However we did build a function called validateTrimAndFill which does 
three things:

1. Check all values and determine if they are within a (generously) reasonable 
range. If they are not, they will be replaced with an NA.
2. Trim each table so that any columns with less than 2 data points are removed.
3. Fill in missing values by taking the mean of 5 imputations using the amelia 
function.

The valid ranges were determined loosely, by examining lowest/highest recorded 
values. This means that we will only find obvious problems, which is fair. 
Using Amelia to fill values may not necessarily be appropriate, but it allows 
the user to easily fill in missing values. Five imputations are performed of the
dataset and values are the mean of these imputations. It would be up to the user
to decide a more rigorous model for interpolation/estimation.

Some sample code is as follows (included in examples):

```{r}
library(ProjectPWS)
data(charlotteStations)

# Just keep two stations
charlotteStations <- makeStationSubtable(charlotteStations,
                       stationNames = c("KNCCHARL71", "KNCCHARL83"))

# Load data for these stations for a single day
loadWeatherData(charlotteStations, startDate = "3/15/2015")

# Just validate
validateTrimAndFill(charlotteStations, stopAfterValidation = TRUE)

# Validate then trim
validateTrimAndFill(charlotteStations, stopAfterTrim = TRUE)

# Validate, trim and fill missing data
validateTrimAndFill(charlotteStations)
```

## Testing
testthat is used to run automated tests on each of the functions (outside of 
shiny). It does some basic tests of invalid input as well as the core 
functionality described here. We limit testing because of the number of calls 
that generally have to be made and would have to invest in a more rigorous 
testing scheme if we were to continue here i.e. improve the design so that we 
could shim the API and run many more tests locally etc.

